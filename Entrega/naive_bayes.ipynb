{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação do Algoritmo Naive Bayes\n",
    "Este notebook contém a implementação do algoritmo Árvore de Decisão do zero, utilizando apenas a biblioteca NumPy, além de uma análise crítica do código gerado e dos resultados obtidos ao aplicá-lo no dataset Penguins.\n",
    "\n",
    "## Prompts Utilizados e Respostas\n",
    "\n",
    "### Prompt 1:\n",
    "\n",
    "Implemente o algoritmo de árvore de decisão from scratch utilizando apenas a biblioteca NumPy para operações vetoriais. A implementação não pode utilizar outras bibliotecas prontas, o teste do algoritmo deve ser feito no dataset penguins_lter.csv na pasta raiz do projeto. Após a implementação e execução do algoritmo, printe na tela o desempenho do modelo utilizando as seguintes métricas: Matriz de confusão, Acurácia, Recall, Precisão, F1-score.\n",
    "\n",
    "### Resposta 1:\n",
    "\n",
    "Aqui está um código completo para a implementação de uma árvore de decisão usando apenas NumPy, incluindo funções para cálculo de entropia, ganho de informação, e divisão do dataset. Também incluiu um exemplo de como carregar o dataset pinguins_lter.csv, treinar o modelo, e calcular as métricas de desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o dataset\n",
    "penguins_df = pd.read_csv('penguins_lter.csv')\n",
    "\n",
    "# Limpar o dataset e selecionar colunas relevantes\n",
    "penguins_cleaned_df = penguins_df[['Species', 'Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']].dropna()\n",
    "\n",
    "# Codificar as espécies em valores numéricos\n",
    "penguins_cleaned_df['Species'] = penguins_cleaned_df['Species'].astype('category').cat.codes\n",
    "\n",
    "# Função para embaralhar os dados\n",
    "def shuffle_data(X, y):\n",
    "    indices = np.arange(len(y))\n",
    "    np.random.shuffle(indices)\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos dados em treino e teste sem usar sklearn\n",
    "def train_test_split(X, y, test_size=0.3, random_state=None):\n",
    "    np.random.seed(random_state)\n",
    "    indices = np.random.permutation(len(X))\n",
    "    test_size = int(len(X) * test_size)\n",
    "    test_indices = indices[:test_size]\n",
    "    train_indices = indices[test_size:]\n",
    "    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "\n",
    "# Preparar os dados\n",
    "X = penguins_cleaned_df[['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']].values\n",
    "y = penguins_cleaned_df['Species'].values\n",
    "\n",
    "# Embaralhar os dados\n",
    "X, y = shuffle_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementação do classificador Naive Bayes\n",
    "class NaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.classes = np.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "\n",
    "        # Inicializar médias, variâncias e priors para cada classe\n",
    "        self.mean = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self.var = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self.priors = np.zeros(n_classes, dtype=np.float64)\n",
    "\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.mean[c, :] = X_c.mean(axis=0)\n",
    "            self.var[c, :] = X_c.var(axis=0)\n",
    "            self.priors[c] = X_c.shape[0] / float(n_samples)\n",
    "\n",
    "    def _gaussian_pdf(self, class_idx, x):\n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        numerator = np.exp(- (x - mean) ** 2 / (2 * var))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        return numerator / denominator\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        posteriors = []\n",
    "\n",
    "        for idx, c in enumerate(self.classes):\n",
    "            prior = np.log(self.priors[idx])\n",
    "            class_conditional = np.sum(np.log(self._gaussian_pdf(idx, x)))\n",
    "            posterior = prior + class_conditional\n",
    "            posteriors.append(posterior)\n",
    "\n",
    "        return self.classes[np.argmax(posteriors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções para calcular as métricas\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    unique_labels = np.unique(y_true)\n",
    "    cm = np.zeros((len(unique_labels), len(unique_labels)), dtype=int)\n",
    "    for i in range(len(y_true)):\n",
    "        cm[y_true[i], y_pred[i]] += 1\n",
    "    return cm\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return np.diag(cm) / np.sum(cm, axis=0)\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return np.diag(cm) / np.sum(cm, axis=1)\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2 * (prec * rec) / (prec + rec)\n",
    "\n",
    "# Função para calcular a média ponderada\n",
    "def weighted_average(metrics, y_true):\n",
    "    classes, counts = np.unique(y_true, return_counts=True)\n",
    "    total = counts.sum()\n",
    "    weighted_metrics = np.sum(metrics * counts[:, None], axis=0) / total\n",
    "    return weighted_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo\n",
    "nb = NaiveBayes()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão:\n",
      "[[41  2  0]\n",
      " [ 1 14  0]\n",
      " [ 0  0 44]]\n",
      "Acurácia: 97.06%\n",
      "Precisão (média ponderada): 0.9504\n",
      "Recall (média ponderada): 0.9623\n",
      "F1 Score (média ponderada): 0.9560\n"
     ]
    }
   ],
   "source": [
    "# Calcular as métricas\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy(y_test, y_pred)\n",
    "prec = precision(y_test, y_pred)\n",
    "rec = recall(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calcular médias ponderadas\n",
    "prec_avg = np.mean(prec)\n",
    "rec_avg = np.mean(rec)\n",
    "f1_avg = np.mean(f1)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(cm)\n",
    "print(f\"Acurácia: {acc * 100:.2f}%\")\n",
    "print(f\"Precisão (média ponderada): {prec_avg:.4f}\")\n",
    "print(f\"Recall (média ponderada): {rec_avg:.4f}\")\n",
    "print(f\"F1 Score (média ponderada): {f1_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Explicação do Código de Naive Bayes\n",
    "\n",
    "1. *Classe NaiveBayes*:\n",
    "    - fit: Treina o modelo com base nos dados de treinamento.\n",
    "    - _gaussian_pdf: Calcula a função de probabilidade gaussiana para uma dada classe.\n",
    "    - predict: Faz previsões para novos dados e retorna a classe com a maior probabilidade.\n",
    "\n",
    "2. *Funções de Métricas*:\n",
    "    - accuracy: Calcula a acurácia.\n",
    "    -  confusion_matrix: Gera uma matriz de confusão.\n",
    "    -  precision: Calcula a precisão da previsão.\n",
    "    -  recall: Calcula o recall da previsão.\n",
    "    -  f1_score: Calcula o F1-score.\n",
    "\n",
    "3. *Carregamento do Dataset*:\n",
    "    - Leitura dos dados: Carrega o dataset de penguins_lter.csv, seleciona colunas importantes e tira valores nulos.\n",
    "\n",
    "4. *Execução do Algoritmo*:\n",
    "    - O dataset é embaralhado aleatoriamente e dividido em 80% para treino e 20% para teste.\n",
    "    - O modelo árvore de decisão é treinado e testado.\n",
    "    - As métricas são calculadas e exibidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de saída\n",
    "Matriz de Confusão:<br>\n",
    "[[41  2  0]<br>\n",
    " [ 1 14  0]<br>\n",
    " [ 0  0 44]]<br>\n",
    "Acurácia: 97.06%<br>\n",
    "Precisão (média ponderada): 0.9504<br>\n",
    "Recall (média ponderada): 0.9623<br>\n",
    "F1 Score (média ponderada): 0.9560"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Crítica do Código Gerado\n",
    "\n",
    "### Pontos Fortes\n",
    "- *Implementação Simples*: O código é direto e fácil de entender.\n",
    "- *Eficaz com poucos dados*: É eficaz em situações onde são poucos dados, pois ainda pode fazer boas previsões, mesmo com um número limitado de amostras.\n",
    "\n",
    "### Potenciais Problemas/Diferenças\n",
    "- *Assunção de Distribuição Normal*: O Naive Bayes Gaussiano assume que os dados seguem uma distribuição normal, o que pode não ser verdade em todos os casos.\n",
    "- *Ausência de Cross-validation*: O código não implementa técnicas de cross-validation, que são importantes para trazer resultados mais reais.\n",
    "\n",
    "### Opções de Projeto e Impacto\n",
    "- *Uso de Logaritmos*: O uso de logaritmos nas probabilidades é uma boa prática para evitar problemas de underflow numérico, especialmente em datasets grandes.\n",
    "\n",
    "### Sugestões de Melhorias\n",
    "- *Adicionar Cross-validation*: Implementar cross-validation para resultados mais realistas.\n",
    "- *Generalizar o Pré-processamento*: Incluir etapas de pré-processamento para lidar com dados categóricos e normalizar os dados numéricos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
