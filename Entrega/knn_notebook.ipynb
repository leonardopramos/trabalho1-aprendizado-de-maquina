{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação do Algoritmo K-Nearest Neighbors (kNN)\n",
    "\n",
    "Este notebook contém a implementação do algoritmo k-Nearest Neighbors (kNN) do zero, utilizando apenas a biblioteca NumPy, além de uma análise crítica do código gerado e dos resultados obtidos ao aplicá-lo no dataset Penguins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts Utilizados e Respostas\n",
    "\n",
    "### Prompt 1:\n",
    "\n",
    "Implemente o algoritmo K-Nearest Neighbors (kNN) from scratch utilizando apenas a biblioteca NumPy para operações vetoriais. A implementação não pode utilizar outra bibliotecas prontas, o teste do algoritmo deve ser feito no dataset penguins_lter.csv na pasta raiz do projeto. Após a implementação e execução do algoritmo, printe na tela o desempenho do modelo utilizando as seguintes métricas:\n",
    "Matriz de confusão\n",
    "Acurácia\n",
    "Recall\n",
    "Precisão\n",
    "F1-score\n",
    "\n",
    "### Resposta 1:\n",
    "\n",
    "Aqui está a implementação do algoritmo K-Nearest Neighbors (kNN) do zero, utilizando apenas a biblioteca NumPy. A implementação será feita na classe knn.py, e será utilizado o dataset Penguins para testar o algoritmo. As métricas solicitadas (matriz de confusão, acurácia, recall, precisão e F1-score) também serão calculadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = [self._predict(x) for x in X_test]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        # Calcula a distância entre x e todos os pontos de treino\n",
    "        distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        # Obtem os k vizinhos mais próximos\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        # Retorna a classe mais comum entre os vizinhos\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred):\n",
    "    unique_labels = np.unique(y_true)\n",
    "    matrix = np.zeros((len(unique_labels), len(unique_labels)), dtype=int)\n",
    "    label_to_index = {label: index for index, label in enumerate(unique_labels)}\n",
    "    \n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        matrix[label_to_index[true], label_to_index[pred]] += 1\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_f1(conf_matrix):\n",
    "    TP = np.diag(conf_matrix)\n",
    "    FP = np.sum(conf_matrix, axis=0) - TP\n",
    "    FN = np.sum(conf_matrix, axis=1) - TP\n",
    "\n",
    "    # Precisão\n",
    "    precision = np.mean(np.divide(TP, (TP + FP), where=(TP + FP) != 0))\n",
    "    # Recall\n",
    "    recall = np.mean(np.divide(TP, (TP + FN), where=(TP + FN) != 0))\n",
    "    # F1-Score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_penguin_dataset(filename='penguins_lter.csv'):\n",
    "    X = []\n",
    "    y = []\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Pular o cabeçalho\n",
    "        for row in reader:\n",
    "            try:\n",
    "                # Selecionar as colunas numéricas: Comprimento do Bico, Profundidade do Bico, Comprimento das Nadadeiras, Massa Corporal\n",
    "                features = [float(row[9]), float(row[10]), float(row[11]), float(row[12])]\n",
    "                species = row[2]  # Usamos \"Species\" como a classe\n",
    "                if '' not in row[9:13]:  # Verifica se não há valores ausentes\n",
    "                    X.append(features)\n",
    "                    y.append(species)\n",
    "            except ValueError:\n",
    "                # Ignorar linhas com valores inválidos\n",
    "                continue\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão:\n",
      "[[20  2  3]\n",
      " [ 6 10  1]\n",
      " [ 2  1 24]]\n",
      "Acurácia: 0.7826\n",
      "Precisão: 0.7802\n",
      "Recall: 0.7590\n",
      "F1-Score: 0.7695\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Carregar dataset de pinguins\n",
    "    X, y = load_penguin_dataset()\n",
    "\n",
    "    # Embaralhar o dataset\n",
    "    indices = np.random.permutation(len(X))\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "\n",
    "    # Dividir em treino e teste (80% treino, 20% teste)\n",
    "    split_ratio = 0.8\n",
    "    split_index = int(split_ratio * len(X))\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "    # Instanciar o modelo\n",
    "    knn = KNN(k=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Fazer previsões\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    # Calcular a matriz de confusão\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Matriz de Confusão:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # Calcular acurácia\n",
    "    acc = accuracy(y_test, y_pred)\n",
    "    print(f\"Acurácia: {acc:.4f}\")\n",
    "\n",
    "    # Calcular precisão, recall e F1-score\n",
    "    precision, recall, f1 = precision_recall_f1(conf_matrix)\n",
    "    print(f\"Precisão: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicação do código:\n",
    "\n",
    "1. *Classe KNN*:\n",
    "   - __init__: Define o valor de k, o número de vizinhos.\n",
    "   - fit: Armazena os dados de treino.\n",
    "   - euclidean_distance: Calcula a distância euclidiana.\n",
    "   - predict: Faz a previsão para o conjunto de dados de teste.\n",
    "\n",
    "2. *Funções de Métricas*:\n",
    "   - accuracy: Calcula a acurácia.\n",
    "   - confusion_matrix: Gera a matriz de confusão.\n",
    "   - precision_recall_f1: Calcula precisão, recall e F1-score.\n",
    "\n",
    "3. *Carregamento do Dataset*:\n",
    "   - load_penguin_dataset: Lê o arquivo penguins_lter.csv e retorna o conjunto de características (X) e as classes (y).\n",
    "\n",
    "4. *Execução do Algoritmo*:\n",
    "   - O dataset é embaralhado aleatoriamente e dividido em 80% para treino e 20% para teste.\n",
    "   - O modelo kNN é treinado e testado.\n",
    "   - As métricas são calculadas e exibidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de Saída:\n",
    "\n",
    "Matriz de Confusão:<br>\n",
    "[[20  2  3]<br>\n",
    " [ 6 10  1]<br>\n",
    " [ 2  1 24]]<br>\n",
    "Acurácia: 0.7826<br>\n",
    "Precisão: 0.7802<br>\n",
    "Recall: 0.7590<br>\n",
    "F1-Score: 0.7695"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Crítica do Código Gerado\n",
    "\n",
    "Testamos o algoritmo KNN para dois datasets diferentes: Iris e Penguins, sendo Penguins o dataset escolhido para a implementação do código.\n",
    "Escolhendo o dataset Iris, vimos que os resultados de métrica são todos muito próximos de 1.0000 ou exatamente 1.0000.\n",
    "Isso pode ter ocasionado por diversos fatores:\n",
    "- *Valor de k muito baixo*: Ocasionando overfitting.\n",
    "- *Tamanho do dataset muito reduzido*\n",
    "- *Falta de cross-validation*\n",
    "\n",
    "Por conta desses fatores, resolvermos optar pelo dataset Penguins, pois temos dados mais realistas, mais bem distribuidos e mais casos de teste.\n",
    "<br><br><br>\n",
    "Em relação ao dataset Penguis:\n",
    "\n",
    "#### Pontos Fortes\n",
    "- *Implementação simples*: O código é direto e fácil de entender, que utiliza o algoritmo kNN.\n",
    "\n",
    "#### Potenciais Problemas/Diferenças\n",
    "- *Divisão Simples de Dados*: A divisão do dataset em treino e teste é feita de forma aleatória e fixa (80/20), sem cross-validation, assim não fazendo a melhor divisão dos dados.\n",
    "- *Escolha de k*: Com o valor de k muito baixo ocorre casos de overfitting e com o valor de k muito alto ocorre casos de underfitting.\n",
    "\n",
    "#### Opções de Projeto e Impacto\n",
    "- *Uso de Distância Euclidiana*: Simples e eficaz para um dataset com dados equilibrados, mas com sensibilidade a outliers.\n",
    "\n",
    "#### Sugestões de Melhorias\n",
    "- *Cross-validation*: Implementar cross-validation para uma melhora divisão dos dados.\n",
    "- *Normalização dos Dados*: Melhora a performance de dados com diferentes escalas.\n",
    "- *Otimização de k*: Testar diferentes valores de k para encontrar o melhor valor para o dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão:\n",
    "Primeiramente, testamos com um dataset pequeno e simples (Iris) e, com essa implementação de algoritmo, obtemos resultados perfeitos, resultados irreais.\n",
    "Por isso optamos por usar o dataset Penguins, que nos mostrou resultados reais, porém com um desempenho não tão satisfatório.\n",
    "Podemos melhorar o algoritmo implementando cross-validation, realizando normalização de dados e achando o valor ideal para k."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
